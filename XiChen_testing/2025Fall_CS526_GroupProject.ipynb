{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSVfdxdgzKqM",
        "outputId": "477257b7-3e49-420e-bc5a-46ff3d881733"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "test colab github\n"
      ],
      "metadata": {
        "id": "O_EA1GptZb1n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                             f1_score, roc_auc_score, classification_report,\n",
        "                             confusion_matrix, precision_recall_curve, roc_curve)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"✓ 库导入成功\")\n",
        "print(f\"PyTorch 版本: {torch.__version__}\")\n",
        "print(f\"CUDA 可用: {torch.cuda.is_available()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyyP49fBItU1",
        "outputId": "b31f3d23-1204-4066-c7db-c08f82548a62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ 库导入成功\n",
            "PyTorch 版本: 2.8.0+cu126\n",
            "CUDA 可用: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*60)\n",
        "print(\"数据加载\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/2025Fall_CS526_GroupProject/readmission_features_30d_v1.csv')\n",
        "\n",
        "print(f\"原始数据形状: {df.shape}\")\n",
        "print(f\"再入院率: {df['readmit_label'].mean():.2%}\")\n",
        "\n",
        "# 删除缺失率高的列（>30%）\n",
        "missing_threshold = 0.30\n",
        "columns_to_keep = df.columns[df.isnull().mean() < missing_threshold].tolist()\n",
        "df_clean = df[columns_to_keep].copy()\n",
        "\n",
        "print(f\"\\n保留列数: {len(columns_to_keep)}\")\n",
        "\n",
        "# 删除有缺失值的行\n",
        "df_clean = df_clean.dropna()\n",
        "print(f\"删除缺失行后: {df_clean.shape}\")\n",
        "print(f\"保留了 {len(df_clean)/len(df)*100:.1f}% 的数据\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13oJffFoPNoC",
        "outputId": "c92a21bc-9f4a-4037-baeb-8a7becb0d18d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "数据加载\n",
            "============================================================\n",
            "原始数据形状: (546028, 51)\n",
            "再入院率: 20.33%\n",
            "\n",
            "保留列数: 46\n",
            "删除缺失行后: (327118, 46)\n",
            "保留了 59.9% 的数据\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*60)\n",
        "print(\"特征工程\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 删除不需要的列\n",
        "columns_to_drop = ['subject_id', 'hadm_id', 'admittime', 'dischtime', 'readmit_label', 'index']\n",
        "columns_to_drop = [col for col in columns_to_drop if col in df_clean.columns]\n",
        "\n",
        "# 分离数值型和分类型特征\n",
        "numeric_cols = df_clean.select_dtypes(include=[np.number]).columns.tolist()\n",
        "categorical_cols = df_clean.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "numeric_features = [col for col in numeric_cols if col not in columns_to_drop]\n",
        "categorical_features = [col for col in categorical_cols if col not in columns_to_drop]\n",
        "\n",
        "print(f\"数值特征: {len(numeric_features)}\")\n",
        "print(f\"分类特征: {len(categorical_features)}\")\n",
        "print(f\"分类特征列表: {categorical_features}\")\n",
        "\n",
        "# 编码分类特征\n",
        "if len(categorical_features) > 0:\n",
        "    for col in categorical_features:\n",
        "        le = LabelEncoder()\n",
        "        df_clean[col + '_encoded'] = le.fit_transform(df_clean[col].astype(str))\n",
        "    feature_columns = numeric_features + [col + '_encoded' for col in categorical_features]\n",
        "else:\n",
        "    feature_columns = numeric_features\n",
        "\n",
        "print(f\"\\n最终特征数: {len(feature_columns)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuBL5_UsPRck",
        "outputId": "a6d2c687-0bb9-47a8-f1e2-6c6c34151c4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "特征工程\n",
            "============================================================\n",
            "数值特征: 33\n",
            "分类特征: 8\n",
            "分类特征列表: ['last_service', 'gender', 'language', 'marital_status', 'insurance', 'admission_type', 'admission_location', 'discharge_location']\n",
            "\n",
            "最终特征数: 41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_clean[feature_columns].values\n",
        "y = df_clean['readmit_label'].values\n",
        "\n",
        "print(f\"特征矩阵形状: {X.shape}\")\n",
        "print(f\"标签形状: {y.shape}\")\n",
        "print(f\"正类比例: {y.mean():.2%}\")\n",
        "print(f\"负类比例: {1-y.mean():.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0zLmJrKPVk5",
        "outputId": "46a1e447-faf3-4b35-af50-b06a6f0f4ade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "特征矩阵形状: (327118, 41)\n",
            "标签形状: (327118,)\n",
            "正类比例: 22.61%\n",
            "负类比例: 77.39%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 划分训练集和测试集\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"训练集: {X_train.shape}, 正类: {y_train.mean():.2%}\")\n",
        "print(f\"测试集: {X_test.shape}, 正类: {y_test.mean():.2%}\")\n",
        "\n",
        "# 标准化\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "print(f\"\\n标准化完成\")\n",
        "print(f\"X_train 范围: [{X_train.min():.2f}, {X_train.max():.2f}]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjLpNsZ-PXir",
        "outputId": "3ec48f10-0e76-4c85-ea38-8e1297e83b26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "训练集: (261694, 41), 正类: 22.61%\n",
            "测试集: (65424, 41), 正类: 22.61%\n",
            "\n",
            "标准化完成\n",
            "X_train 范围: [-12.79, 510.56]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ReadmissionDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.FloatTensor(X)\n",
        "        self.y = torch.LongTensor(y)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "# 创建 Dataset\n",
        "train_dataset = ReadmissionDataset(X_train, y_train)\n",
        "test_dataset = ReadmissionDataset(X_test, y_test)\n",
        "\n",
        "# 创建 DataLoader\n",
        "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False, pin_memory=True)\n",
        "\n",
        "print(f\"✓ DataLoader 创建成功\")\n",
        "print(f\"训练批次数: {len(train_loader)}\")\n",
        "print(f\"测试批次数: {len(test_loader)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVcUO0PwPZ82",
        "outputId": "4ce7d705-130b-4667-b050-5be4fc1d1613"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ DataLoader 创建成功\n",
            "训练批次数: 1023\n",
            "测试批次数: 256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, d_model=256, nhead=8, num_layers=3, dropout=0.2):\n",
        "        super(TransformerClassifier, self).__init__()\n",
        "\n",
        "        # 输入投影层\n",
        "        self.input_projection = nn.Sequential(\n",
        "            nn.Linear(input_dim, d_model),\n",
        "            nn.LayerNorm(d_model),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "        # 位置编码\n",
        "        self.pos_encoding = nn.Parameter(torch.randn(1, 1, d_model) * 0.02)\n",
        "\n",
        "        # Transformer Encoder\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=d_model * 4,\n",
        "            dropout=dropout,\n",
        "            activation='gelu',\n",
        "            batch_first=True,\n",
        "            norm_first=True  # Pre-LN，更稳定\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(\n",
        "            encoder_layer,\n",
        "            num_layers=num_layers,\n",
        "            norm=nn.LayerNorm(d_model)\n",
        "        )\n",
        "\n",
        "        # 分类头\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(d_model, d_model // 2),\n",
        "            nn.LayerNorm(d_model // 2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(d_model // 2, d_model // 4),\n",
        "            nn.LayerNorm(d_model // 4),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout * 0.5),\n",
        "            nn.Linear(d_model // 4, 2)\n",
        "        )\n",
        "\n",
        "        # 初始化\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 投影到 d_model 维度\n",
        "        x = self.input_projection(x)\n",
        "\n",
        "        # 添加维度以适配 Transformer\n",
        "        x = x.unsqueeze(1)\n",
        "\n",
        "        # 添加位置编码\n",
        "        x = x + self.pos_encoding\n",
        "\n",
        "        # Transformer 编码\n",
        "        x = self.transformer_encoder(x)\n",
        "\n",
        "        # 取出序列表示\n",
        "        x = x.squeeze(1)\n",
        "\n",
        "        # 分类\n",
        "        out = self.classifier(x)\n",
        "\n",
        "        return out\n",
        "\n",
        "print(\"✓ Transformer 模型定义完成\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWobI-sJPb7q",
        "outputId": "297322fb-fbca-4e98-8e21-6868f6a666b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Transformer 模型定义完成\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"使用设备: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "# 创建模型\n",
        "model = TransformerClassifier(\n",
        "    input_dim=X_train.shape[1],\n",
        "    d_model=256,\n",
        "    nhead=8,\n",
        "    num_layers=3,\n",
        "    dropout=0.2\n",
        ").to(device)\n",
        "\n",
        "print(f\"\\n模型参数量: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "# 计算类别权重\n",
        "class_counts = np.bincount(y_train)\n",
        "class_weights = torch.FloatTensor([1.0, class_counts[0] / class_counts[1]]).to(device)\n",
        "print(f\"类别权重: {class_weights.cpu().numpy()}\")\n",
        "\n",
        "# 损失函数\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "# 优化器\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=0.0001,\n",
        "    weight_decay=0.01,\n",
        "    betas=(0.9, 0.999)\n",
        ")\n",
        "\n",
        "# 学习率调度器\n",
        "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
        "scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)\n",
        "\n",
        "print(\"✓ 模型和优化器初始化完成\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOiuwitVPeVV",
        "outputId": "6acdcbaf-d6bc-4858-bb74-534e751fb4ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "使用设备: cuda\n",
            "GPU: NVIDIA A100-SXM4-40GB\n",
            "\n",
            "模型参数量: 2,422,978\n",
            "类别权重: [1.       3.422748]\n",
            "✓ 模型和优化器初始化完成\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, loader, criterion, optimizer, scheduler, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    for X_batch, y_batch in loader:\n",
        "        X_batch = X_batch.to(device, non_blocking=True)\n",
        "        y_batch = y_batch.to(device, non_blocking=True)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        loss.backward()\n",
        "\n",
        "        # 梯度裁剪\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(y_batch.cpu().numpy())\n",
        "\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    return total_loss / len(loader), acc\n",
        "\n",
        "def evaluate(model, loader, device):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    all_probs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in loader:\n",
        "            X_batch = X_batch.to(device, non_blocking=True)\n",
        "            outputs = model(X_batch)\n",
        "            probs = torch.softmax(outputs, dim=1)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(y_batch.cpu().numpy())\n",
        "            all_probs.extend(probs[:, 1].cpu().numpy())\n",
        "\n",
        "    return np.array(all_preds), np.array(all_labels), np.array(all_probs)\n",
        "\n",
        "print(\"✓ 训练和评估函数定义完成\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WDqjQX8Pgb7",
        "outputId": "8da60d62-e212-4377-9821-acf5a945e880"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ 训练和评估函数定义完成\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*60)\n",
        "print(\"开始训练 Transformer\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "num_epochs = 100\n",
        "best_auc = 0\n",
        "best_f1 = 0\n",
        "patience = 15\n",
        "patience_counter = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, scheduler, device)\n",
        "    preds, labels, probs = evaluate(model, test_loader, device)\n",
        "\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    precision = precision_score(labels, preds, zero_division=0)\n",
        "    recall = recall_score(labels, preds, zero_division=0)\n",
        "    f1 = f1_score(labels, preds, zero_division=0)\n",
        "    auc = roc_auc_score(labels, probs)\n",
        "\n",
        "    # 每5个epoch打印一次\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "        print(f\"  Train - Loss: {train_loss:.4f}, Acc: {train_acc:.4f}\")\n",
        "        print(f\"  Test  - Acc: {acc:.4f}, Prec: {precision:.4f}, Rec: {recall:.4f}\")\n",
        "        print(f\"  Test  - F1: {f1:.4f}, AUC: {auc:.4f}\")\n",
        "        print(f\"  LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "\n",
        "    # 保存最佳模型\n",
        "    if auc > best_auc:\n",
        "        best_auc = auc\n",
        "        best_f1 = f1\n",
        "        torch.save(model.state_dict(), 'best_transformer_model.pth')\n",
        "        patience_counter = 0\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            print(\"  ✓ 保存最佳模型\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "\n",
        "    # 早停\n",
        "    if patience_counter >= patience:\n",
        "        print(f\"\\n早停于 Epoch {epoch+1}\")\n",
        "        break\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"训练完成！\")\n",
        "print(f\"最佳 AUC: {best_auc:.4f}\")\n",
        "print(f\"最佳 F1: {best_f1:.4f}\")\n",
        "print(f\"{'='*60}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCoqc9akPiYs",
        "outputId": "1961d83e-4f07-40d7-c719-1d8d66973535"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "开始训练 Transformer\n",
            "============================================================\n",
            "\n",
            "Epoch 5/100\n",
            "  Train - Loss: 0.6376, Acc: 0.6246\n",
            "  Test  - Acc: 0.6285, Prec: 0.3329, Rec: 0.6405\n",
            "  Test  - F1: 0.4381, AUC: 0.6863\n",
            "  LR: 0.000100\n",
            "  ✓ 保存最佳模型\n",
            "\n",
            "Epoch 10/100\n",
            "  Train - Loss: 0.6319, Acc: 0.6292\n",
            "  Test  - Acc: 0.6263, Prec: 0.3325, Rec: 0.6480\n",
            "  Test  - F1: 0.4395, AUC: 0.6900\n",
            "  LR: 0.000100\n",
            "  ✓ 保存最佳模型\n",
            "\n",
            "Epoch 15/100\n",
            "  Train - Loss: 0.6297, Acc: 0.6331\n",
            "  Test  - Acc: 0.6062, Prec: 0.3257, Rec: 0.6929\n",
            "  Test  - F1: 0.4431, AUC: 0.6924\n",
            "  LR: 0.000051\n",
            "  ✓ 保存最佳模型\n",
            "\n",
            "Epoch 20/100\n",
            "  Train - Loss: 0.6272, Acc: 0.6355\n",
            "  Test  - Acc: 0.6385, Prec: 0.3402, Rec: 0.6375\n",
            "  Test  - F1: 0.4437, AUC: 0.6942\n",
            "  LR: 0.000001\n",
            "  ✓ 保存最佳模型\n",
            "\n",
            "Epoch 25/100\n",
            "  Train - Loss: 0.6269, Acc: 0.6359\n",
            "  Test  - Acc: 0.6320, Prec: 0.3371, Rec: 0.6497\n",
            "  Test  - F1: 0.4439, AUC: 0.6956\n",
            "  LR: 0.000086\n",
            "  ✓ 保存最佳模型\n",
            "\n",
            "Epoch 30/100\n",
            "  Train - Loss: 0.6241, Acc: 0.6386\n",
            "  Test  - Acc: 0.6377, Prec: 0.3402, Rec: 0.6415\n",
            "  Test  - F1: 0.4446, AUC: 0.6966\n",
            "  LR: 0.000051\n",
            "  ✓ 保存最佳模型\n",
            "\n",
            "Epoch 35/100\n",
            "  Train - Loss: 0.6222, Acc: 0.6427\n",
            "  Test  - Acc: 0.6445, Prec: 0.3438, Rec: 0.6301\n",
            "  Test  - F1: 0.4449, AUC: 0.6975\n",
            "  LR: 0.000016\n",
            "\n",
            "Epoch 40/100\n",
            "  Train - Loss: 0.6212, Acc: 0.6431\n",
            "  Test  - Acc: 0.6464, Prec: 0.3450, Rec: 0.6274\n",
            "  Test  - F1: 0.4452, AUC: 0.6978\n",
            "  LR: 0.000001\n",
            "  ✓ 保存最佳模型\n",
            "\n",
            "Epoch 45/100\n",
            "  Train - Loss: 0.6228, Acc: 0.6417\n",
            "  Test  - Acc: 0.6643, Prec: 0.3552, Rec: 0.5951\n",
            "  Test  - F1: 0.4449, AUC: 0.6978\n",
            "  LR: 0.000096\n",
            "  ✓ 保存最佳模型\n",
            "\n",
            "Epoch 50/100\n",
            "  Train - Loss: 0.6210, Acc: 0.6447\n",
            "  Test  - Acc: 0.6284, Prec: 0.3366, Rec: 0.6628\n",
            "  Test  - F1: 0.4465, AUC: 0.6976\n",
            "  LR: 0.000086\n",
            "\n",
            "Epoch 55/100\n",
            "  Train - Loss: 0.6188, Acc: 0.6463\n",
            "  Test  - Acc: 0.6355, Prec: 0.3403, Rec: 0.6520\n",
            "  Test  - F1: 0.4472, AUC: 0.6985\n",
            "  LR: 0.000070\n",
            "\n",
            "Epoch 60/100\n",
            "  Train - Loss: 0.6166, Acc: 0.6488\n",
            "  Test  - Acc: 0.6526, Prec: 0.3485, Rec: 0.6174\n",
            "  Test  - F1: 0.4455, AUC: 0.6989\n",
            "  LR: 0.000051\n",
            "\n",
            "Epoch 65/100\n",
            "  Train - Loss: 0.6153, Acc: 0.6516\n",
            "  Test  - Acc: 0.6529, Prec: 0.3493, Rec: 0.6205\n",
            "  Test  - F1: 0.4470, AUC: 0.6997\n",
            "  LR: 0.000032\n",
            "  ✓ 保存最佳模型\n",
            "\n",
            "Epoch 70/100\n",
            "  Train - Loss: 0.6136, Acc: 0.6545\n",
            "  Test  - Acc: 0.6453, Prec: 0.3448, Rec: 0.6319\n",
            "  Test  - F1: 0.4461, AUC: 0.6991\n",
            "  LR: 0.000016\n",
            "\n",
            "Epoch 75/100\n",
            "  Train - Loss: 0.6130, Acc: 0.6527\n",
            "  Test  - Acc: 0.6512, Prec: 0.3482, Rec: 0.6226\n",
            "  Test  - F1: 0.4467, AUC: 0.6996\n",
            "  LR: 0.000005\n",
            "\n",
            "Epoch 80/100\n",
            "  Train - Loss: 0.6124, Acc: 0.6535\n",
            "  Test  - Acc: 0.6509, Prec: 0.3482, Rec: 0.6244\n",
            "  Test  - F1: 0.4471, AUC: 0.6996\n",
            "  LR: 0.000001\n",
            "\n",
            "早停于 Epoch 82\n",
            "\n",
            "============================================================\n",
            "训练完成！\n",
            "最佳 AUC: 0.7000\n",
            "最佳 F1: 0.4468\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*60)\n",
        "print(\"最终模型评估\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 加载最佳模型\n",
        "model.load_state_dict(torch.load('best_transformer_model.pth'))\n",
        "preds, labels, probs = evaluate(model, test_loader, device)\n",
        "\n",
        "print(f\"\\nAccuracy:  {accuracy_score(labels, preds):.4f}\")\n",
        "print(f\"Precision: {precision_score(labels, preds):.4f}\")\n",
        "print(f\"Recall:    {recall_score(labels, preds):.4f}\")\n",
        "print(f\"F1 Score:  {f1_score(labels, preds):.4f}\")\n",
        "print(f\"AUC-ROC:   {roc_auc_score(labels, probs):.4f}\")\n",
        "\n",
        "print(\"\\n分类报告:\")\n",
        "print(classification_report(labels, preds, target_names=['无再入院', '再入院']))\n",
        "\n",
        "cm = confusion_matrix(labels, preds)\n",
        "print(f\"\\n混淆矩阵:\")\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuDeHdGvPl5c",
        "outputId": "b26e1825-f088-418d-96c9-4107943544a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "最终模型评估\n",
            "============================================================\n",
            "\n",
            "Accuracy:  0.6435\n",
            "Precision: 0.3441\n",
            "Recall:    0.6368\n",
            "F1 Score:  0.4468\n",
            "AUC-ROC:   0.7000\n",
            "\n",
            "分类报告:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        无再入院       0.86      0.65      0.74     50632\n",
            "         再入院       0.34      0.64      0.45     14792\n",
            "\n",
            "    accuracy                           0.64     65424\n",
            "   macro avg       0.60      0.64      0.59     65424\n",
            "weighted avg       0.74      0.64      0.67     65424\n",
            "\n",
            "\n",
            "混淆矩阵:\n",
            "[[32681 17951]\n",
            " [ 5373  9419]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*60)\n",
        "print(\"阈值优化\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "precisions, recalls, thresholds = precision_recall_curve(labels, probs)\n",
        "f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-10)\n",
        "best_idx = np.argmax(f1_scores)\n",
        "best_threshold = thresholds[best_idx]\n",
        "\n",
        "print(f\"\\n最佳阈值: {best_threshold:.3f} (默认是 0.5)\")\n",
        "print(f\"在该阈值下:\")\n",
        "print(f\"  Precision: {precisions[best_idx]:.4f}\")\n",
        "print(f\"  Recall: {recalls[best_idx]:.4f}\")\n",
        "print(f\"  F1: {f1_scores[best_idx]:.4f}\")\n",
        "\n",
        "new_preds = (probs >= best_threshold).astype(int)\n",
        "print(f\"\\n使用优化阈值的最终结果:\")\n",
        "print(f\"  Accuracy:  {accuracy_score(labels, new_preds):.4f}\")\n",
        "print(f\"  Precision: {precision_score(labels, new_preds):.4f}\")\n",
        "print(f\"  Recall:    {recall_score(labels, new_preds):.4f}\")\n",
        "print(f\"  F1 Score:  {f1_score(labels, new_preds):.4f}\")"
      ],
      "metadata": {
        "id": "GTTuDnCYPpjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ROC 曲线\n",
        "fpr, tpr, _ = roc_curve(labels, probs)\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(fpr, tpr, label=f'AUC = {best_auc:.3f}', linewidth=2)\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random', linewidth=1)\n",
        "plt.xlabel('False Positive Rate', fontsize=12)\n",
        "plt.ylabel('True Positive Rate', fontsize=12)\n",
        "plt.title('ROC Curve', fontsize=14)\n",
        "plt.legend(fontsize=11)\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Precision-Recall 曲线\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(recalls, precisions, linewidth=2)\n",
        "plt.xlabel('Recall', fontsize=12)\n",
        "plt.ylabel('Precision', fontsize=12)\n",
        "plt.title('Precision-Recall Curve', fontsize=14)\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('transformer_results.png', dpi=150, bbox_inches='tight')\n",
        "print(\"✓ 图表已保存\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qS0SDk2sPsYx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}