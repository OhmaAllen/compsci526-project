{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86cd756c",
   "metadata": {},
   "source": [
    "# Preprocessing + 30-day Readmission Notebook\n",
    "\n",
    "This focused notebook extracts and documents the preprocessing steps used to build the 30-day readmission label and the pooled static + time-series features. It is a smaller workspace for iterative experiments (safe to run on a dev machine).\n",
    "\n",
    "Key contents:\n",
    "- DATA_DIR setup and quick preview of CSVs\n",
    "- 30-day readmission label computation\n",
    "- Loading patients/diagnoses/chartevents/labevents (with date parsing)\n",
    "- Age computation using `anchor_age` and `anchor_year`\n",
    "- Static features and pooled time-series feature construction\n",
    "- Imputation, scaling, and simple CV training for baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6fdd967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_DIR = /Users/yuchenzhou/documents/duke/compsci526/final_proj/mimic-iv-3.1\n",
      "--- admissions -> /Users/yuchenzhou/documents/duke/compsci526/final_proj/mimic-iv-3.1/hosp/admissions.csv\n",
      "columns: ['subject_id', 'hadm_id', 'admittime', 'dischtime', 'deathtime', 'admission_type', 'admit_provider_id', 'admission_location', 'discharge_location', 'insurance', 'language', 'marital_status', 'race', 'edregtime', 'edouttime', 'hospital_expire_flag']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>admittime</th>\n",
       "      <th>dischtime</th>\n",
       "      <th>deathtime</th>\n",
       "      <th>admission_type</th>\n",
       "      <th>admit_provider_id</th>\n",
       "      <th>admission_location</th>\n",
       "      <th>discharge_location</th>\n",
       "      <th>insurance</th>\n",
       "      <th>language</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>race</th>\n",
       "      <th>edregtime</th>\n",
       "      <th>edouttime</th>\n",
       "      <th>hospital_expire_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>2180-05-06 22:23:00</td>\n",
       "      <td>2180-05-07 17:15:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>URGENT</td>\n",
       "      <td>P49AFC</td>\n",
       "      <td>TRANSFER FROM HOSPITAL</td>\n",
       "      <td>HOME</td>\n",
       "      <td>Medicaid</td>\n",
       "      <td>English</td>\n",
       "      <td>WIDOWED</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>2180-05-06 19:17:00</td>\n",
       "      <td>2180-05-06 23:30:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22841357</td>\n",
       "      <td>2180-06-26 18:27:00</td>\n",
       "      <td>2180-06-27 18:49:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EW EMER.</td>\n",
       "      <td>P784FA</td>\n",
       "      <td>EMERGENCY ROOM</td>\n",
       "      <td>HOME</td>\n",
       "      <td>Medicaid</td>\n",
       "      <td>English</td>\n",
       "      <td>WIDOWED</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>2180-06-26 15:54:00</td>\n",
       "      <td>2180-06-26 21:31:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000032</td>\n",
       "      <td>25742920</td>\n",
       "      <td>2180-08-05 23:44:00</td>\n",
       "      <td>2180-08-07 17:50:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EW EMER.</td>\n",
       "      <td>P19UTS</td>\n",
       "      <td>EMERGENCY ROOM</td>\n",
       "      <td>HOSPICE</td>\n",
       "      <td>Medicaid</td>\n",
       "      <td>English</td>\n",
       "      <td>WIDOWED</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>2180-08-05 20:58:00</td>\n",
       "      <td>2180-08-06 01:44:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id            admittime            dischtime  deathtime  \\\n",
       "0    10000032  22595853  2180-05-06 22:23:00  2180-05-07 17:15:00        NaN   \n",
       "1    10000032  22841357  2180-06-26 18:27:00  2180-06-27 18:49:00        NaN   \n",
       "2    10000032  25742920  2180-08-05 23:44:00  2180-08-07 17:50:00        NaN   \n",
       "\n",
       "  admission_type admit_provider_id      admission_location discharge_location  \\\n",
       "0         URGENT            P49AFC  TRANSFER FROM HOSPITAL               HOME   \n",
       "1       EW EMER.            P784FA          EMERGENCY ROOM               HOME   \n",
       "2       EW EMER.            P19UTS          EMERGENCY ROOM            HOSPICE   \n",
       "\n",
       "  insurance language marital_status   race            edregtime  \\\n",
       "0  Medicaid  English        WIDOWED  WHITE  2180-05-06 19:17:00   \n",
       "1  Medicaid  English        WIDOWED  WHITE  2180-06-26 15:54:00   \n",
       "2  Medicaid  English        WIDOWED  WHITE  2180-08-05 20:58:00   \n",
       "\n",
       "             edouttime  hospital_expire_flag  \n",
       "0  2180-05-06 23:30:00                     0  \n",
       "1  2180-06-26 21:31:00                     0  \n",
       "2  2180-08-06 01:44:00                     0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- patients -> /Users/yuchenzhou/documents/duke/compsci526/final_proj/mimic-iv-3.1/hosp/patients.csv\n",
      "columns: ['subject_id', 'gender', 'anchor_age', 'anchor_year', 'anchor_year_group', 'dod']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>anchor_age</th>\n",
       "      <th>anchor_year</th>\n",
       "      <th>anchor_year_group</th>\n",
       "      <th>dod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000032</td>\n",
       "      <td>F</td>\n",
       "      <td>52</td>\n",
       "      <td>2180</td>\n",
       "      <td>2014 - 2016</td>\n",
       "      <td>2180-09-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000048</td>\n",
       "      <td>F</td>\n",
       "      <td>23</td>\n",
       "      <td>2126</td>\n",
       "      <td>2008 - 2010</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000058</td>\n",
       "      <td>F</td>\n",
       "      <td>33</td>\n",
       "      <td>2168</td>\n",
       "      <td>2020 - 2022</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id gender  anchor_age  anchor_year anchor_year_group         dod\n",
       "0    10000032      F          52         2180       2014 - 2016  2180-09-09\n",
       "1    10000048      F          23         2126       2008 - 2010         NaN\n",
       "2    10000058      F          33         2168       2020 - 2022         NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- diagnoses_icd -> /Users/yuchenzhou/documents/duke/compsci526/final_proj/mimic-iv-3.1/hosp/diagnoses_icd.csv\n",
      "columns: ['subject_id', 'hadm_id', 'seq_num', 'icd_code', 'icd_version']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>seq_num</th>\n",
       "      <th>icd_code</th>\n",
       "      <th>icd_version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>1</td>\n",
       "      <td>5723</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>2</td>\n",
       "      <td>78959</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>3</td>\n",
       "      <td>5715</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id  seq_num  icd_code  icd_version\n",
       "0    10000032  22595853        1      5723            9\n",
       "1    10000032  22595853        2     78959            9\n",
       "2    10000032  22595853        3      5715            9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- chartevents -> /Users/yuchenzhou/documents/duke/compsci526/final_proj/mimic-iv-3.1/icu/chartevents.csv\n",
      "columns: ['subject_id', 'hadm_id', 'stay_id', 'caregiver_id', 'charttime', 'storetime', 'itemid', 'value', 'valuenum', 'valueuom', 'warning']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>stay_id</th>\n",
       "      <th>caregiver_id</th>\n",
       "      <th>charttime</th>\n",
       "      <th>storetime</th>\n",
       "      <th>itemid</th>\n",
       "      <th>value</th>\n",
       "      <th>valuenum</th>\n",
       "      <th>valueuom</th>\n",
       "      <th>warning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000032</td>\n",
       "      <td>29079034</td>\n",
       "      <td>39553978</td>\n",
       "      <td>18704</td>\n",
       "      <td>2180-07-23 12:36:00</td>\n",
       "      <td>2180-07-23 14:45:00</td>\n",
       "      <td>226512</td>\n",
       "      <td>39.4</td>\n",
       "      <td>39.4</td>\n",
       "      <td>kg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000032</td>\n",
       "      <td>29079034</td>\n",
       "      <td>39553978</td>\n",
       "      <td>18704</td>\n",
       "      <td>2180-07-23 12:36:00</td>\n",
       "      <td>2180-07-23 14:45:00</td>\n",
       "      <td>226707</td>\n",
       "      <td>60</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Inch</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000032</td>\n",
       "      <td>29079034</td>\n",
       "      <td>39553978</td>\n",
       "      <td>18704</td>\n",
       "      <td>2180-07-23 12:36:00</td>\n",
       "      <td>2180-07-23 14:45:00</td>\n",
       "      <td>226730</td>\n",
       "      <td>152</td>\n",
       "      <td>152.0</td>\n",
       "      <td>cm</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id   stay_id  caregiver_id            charttime  \\\n",
       "0    10000032  29079034  39553978         18704  2180-07-23 12:36:00   \n",
       "1    10000032  29079034  39553978         18704  2180-07-23 12:36:00   \n",
       "2    10000032  29079034  39553978         18704  2180-07-23 12:36:00   \n",
       "\n",
       "             storetime  itemid value  valuenum valueuom  warning  \n",
       "0  2180-07-23 14:45:00  226512  39.4      39.4       kg        0  \n",
       "1  2180-07-23 14:45:00  226707    60      60.0     Inch        0  \n",
       "2  2180-07-23 14:45:00  226730   152     152.0       cm        0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- labevents -> /Users/yuchenzhou/documents/duke/compsci526/final_proj/mimic-iv-3.1/hosp/labevents.csv\n",
      "columns: ['labevent_id', 'subject_id', 'hadm_id', 'specimen_id', 'itemid', 'order_provider_id', 'charttime', 'storetime', 'value', 'valuenum', 'valueuom', 'ref_range_lower', 'ref_range_upper', 'flag', 'priority', 'comments']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labevent_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>specimen_id</th>\n",
       "      <th>itemid</th>\n",
       "      <th>order_provider_id</th>\n",
       "      <th>charttime</th>\n",
       "      <th>storetime</th>\n",
       "      <th>value</th>\n",
       "      <th>valuenum</th>\n",
       "      <th>valueuom</th>\n",
       "      <th>ref_range_lower</th>\n",
       "      <th>ref_range_upper</th>\n",
       "      <th>flag</th>\n",
       "      <th>priority</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10000032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2704548</td>\n",
       "      <td>50931</td>\n",
       "      <td>P69FQC</td>\n",
       "      <td>2180-03-23 11:51:00</td>\n",
       "      <td>2180-03-23 15:56:00</td>\n",
       "      <td>___</td>\n",
       "      <td>95.0</td>\n",
       "      <td>mg/dL</td>\n",
       "      <td>70.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ROUTINE</td>\n",
       "      <td>IF FASTING, 70-100 NORMAL, &gt;125 PROVISIONAL DI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10000032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36092842</td>\n",
       "      <td>51071</td>\n",
       "      <td>P69FQC</td>\n",
       "      <td>2180-03-23 11:51:00</td>\n",
       "      <td>2180-03-23 16:00:00</td>\n",
       "      <td>NEG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ROUTINE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10000032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36092842</td>\n",
       "      <td>51074</td>\n",
       "      <td>P69FQC</td>\n",
       "      <td>2180-03-23 11:51:00</td>\n",
       "      <td>2180-03-23 16:00:00</td>\n",
       "      <td>NEG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ROUTINE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labevent_id  subject_id  hadm_id  specimen_id  itemid order_provider_id  \\\n",
       "0            1    10000032      NaN      2704548   50931            P69FQC   \n",
       "1            2    10000032      NaN     36092842   51071            P69FQC   \n",
       "2            3    10000032      NaN     36092842   51074            P69FQC   \n",
       "\n",
       "             charttime            storetime value  valuenum valueuom  \\\n",
       "0  2180-03-23 11:51:00  2180-03-23 15:56:00   ___      95.0    mg/dL   \n",
       "1  2180-03-23 11:51:00  2180-03-23 16:00:00   NEG       NaN      NaN   \n",
       "2  2180-03-23 11:51:00  2180-03-23 16:00:00   NEG       NaN      NaN   \n",
       "\n",
       "   ref_range_lower  ref_range_upper  flag priority  \\\n",
       "0             70.0            100.0   NaN  ROUTINE   \n",
       "1              NaN              NaN   NaN  ROUTINE   \n",
       "2              NaN              NaN   NaN  ROUTINE   \n",
       "\n",
       "                                            comments  \n",
       "0  IF FASTING, 70-100 NORMAL, >125 PROVISIONAL DI...  \n",
       "1                                                NaN  \n",
       "2                                                NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DATA_DIR and quick preview (copy of template)\n",
    "import os, pandas as pd\n",
    "DATA_DIR = '/Users/yuchenzhou/documents/duke/compsci526/final_proj/mimic-iv-3.1'\n",
    "print('DATA_DIR =', DATA_DIR)\n",
    "paths = {\n",
    "    'admissions': os.path.join(DATA_DIR, 'hosp', 'admissions.csv'),\n",
    "    'patients': os.path.join(DATA_DIR, 'hosp', 'patients.csv'),\n",
    "    'diagnoses_icd': os.path.join(DATA_DIR, 'hosp', 'diagnoses_icd.csv'),\n",
    "    'chartevents': os.path.join(DATA_DIR, 'icu', 'chartevents.csv'),\n",
    "    'labevents': os.path.join(DATA_DIR, 'hosp', 'labevents.csv'),\n",
    "}\n",
    "from IPython.display import display\n",
    "for name, p in paths.items():\n",
    "    print('---', name, '->', p)\n",
    "    if os.path.exists(p):\n",
    "        try:\n",
    "            df = pd.read_csv(p, nrows=5)\n",
    "            print('columns:', list(df.columns))\n",
    "            display(df.head(3))\n",
    "        except Exception as e:\n",
    "            print('读取失败:', e)\n",
    "    else:\n",
    "        print('NOT FOUND')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b49e21eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed readmit_30d, distribution:\n",
      "readmit_30d\n",
      "0    80.3\n",
      "1    19.7\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 30-day readmission label (copy of working code)\n",
    "import pandas as pd\n",
    "def _parse_dates_if_exists(df, cols):\n",
    "    for col in cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "    return df\n",
    "admissions = pd.read_csv(os.path.join(DATA_DIR, 'hosp', 'admissions.csv'))\n",
    "admissions = _parse_dates_if_exists(admissions, ['admittime', 'dischtime', 'deathtime', 'edregtime', 'edouttime'])\n",
    "admissions = admissions.sort_values(['subject_id', 'admittime']).reset_index(drop=True)\n",
    "readmit_30d = []\n",
    "for idx, row in admissions.iterrows():\n",
    "    subject_id = row['subject_id']\n",
    "    hadm_id = row['hadm_id']\n",
    "    dischtime = row['dischtime']\n",
    "    if pd.isna(dischtime):\n",
    "        readmit_30d.append(0)\n",
    "        continue\n",
    "    future_admissions = admissions[\n",
    "        (admissions['subject_id'] == subject_id) &\n",
    "        (admissions['hadm_id'] != hadm_id) &\n",
    "        (admissions['admittime'] > dischtime)\n",
    "    ]\n",
    "    if not future_admissions.empty:\n",
    "        next_admit = future_admissions.iloc[0]['admittime']\n",
    "        days_to_readmit = (next_admit - dischtime).total_seconds() / (24*3600)\n",
    "        readmit_30d.append(1 if days_to_readmit <= 30 else 0)\n",
    "    else:\n",
    "        readmit_30d.append(0)\n",
    "admissions['readmit_30d'] = readmit_30d\n",
    "print('Computed readmit_30d, distribution:')\n",
    "print(admissions['readmit_30d'].value_counts(normalize=True).mul(100).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8ab264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load patients/diagnoses and time-series (with date parsing)\n",
    "def _read(path, **kwargs):\n",
    "    if os.path.exists(path):\n",
    "        return pd.read_csv(path, **kwargs)\n",
    "    raise FileNotFoundError(path)\n",
    "patients = _read(os.path.join(DATA_DIR, 'hosp', 'patients.csv'))\n",
    "diagnoses = _read(os.path.join(DATA_DIR, 'hosp', 'diagnoses_icd.csv'))\n",
    "print('Reading small heads:')\n",
    "print(patients.head(2))\n",
    "print(diagnoses.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0583c8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static features and pooled time-series features (copy of functions)\n",
    "admissions = admissions.merge(patients[['subject_id','anchor_age','anchor_year']], on='subject_id', how='left')\n",
    "admissions['admit_year'] = admissions['admittime'].dt.year\n",
    "admissions['age'] = admissions['anchor_age'] + (admissions['admit_year'] - admissions['anchor_year'])\n",
    "admissions['age'] = admissions['age'].clip(lower=0)\n",
    "admissions['los_days'] = (admissions['dischtime'] - admissions['admittime']).dt.total_seconds()/(3600*24)\n",
    "static_df = admissions[['subject_id','hadm_id','age','los_days','readmit_30d']].drop_duplicates().reset_index(drop=True)\n",
    "print('static_df sample:')\n",
    "print(static_df.head())\n",
    "# For full time-series pooling we reference chartevents and labevents; those are large and may be filtered in practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7581da",
   "metadata": {},
   "source": [
    "## Preprocessing summary\n",
    "- Parsed `admittime`/`dischtime`/`charttime` where present.\n",
    "- Constructed `readmit_30d` by checking the next admission within 30 days after discharge for the same `subject_id`.\n",
    "- Computed approximate `age` using `anchor_age` and `anchor_year`.\n",
    "- Built `static_df` with `age`, `los_days`, and the `readmit_30d` label.\n",
    "- Time-series pooling and imputation code (copied to template) produces `X_ts_imputed` and pooled summary features.\n",
    "\n",
    "Detailed reasoning for each preprocessing step (why I do it):\n",
    "\n",
    "- Date parsing (admittime/dischtime/charttime):\n",
    "  - Why: time calculations (length-of-stay, event windows, time-based labels) require proper datetime types. Parsing with `errors='coerce'` avoids crashes when a few malformed rows exist.\n",
    "  - Risk/caveat: coerce converts bad values to NaT; inspect parsing rates for unexpected drops.\n",
    "\n",
    "- Compute 30-day readmission label (`readmit_30d`):\n",
    "  - Why: the project's primary outcome is whether the patient returns within 30 days. Using the same `subject_id` and comparing `admittime` > `dischtime` is robust to overlapping stays and ordering.\n",
    "  - Choices made: we consider the *next* admission chronologically for that patient; alternative definitions (any admission within 30 days, excluding planned readmissions) can be implemented later.\n",
    "  - Caveat: planned readmissions and transfers should be excluded for some analyses; add filters if you have those flags.\n",
    "\n",
    "- Age estimation using `anchor_age` / `anchor_year`:\n",
    "  - Why: this MIMIC-IV export doesn't include `dob`, so `anchor_age` + (admit_year - anchor_year) gives an approximate age at admission.\n",
    "  - Caveat: this is approximate and may be off by a year or two due to anchor-year bucketing.\n",
    "\n",
    "- Static feature selection (age, gender, LOS):\n",
    "  - Why: these are baseline covariates known to correlate with readmission risk and are cheap to compute. Keep the set small for the smoke test; expand later.\n",
    "\n",
    "- Time-window selection and pooling (72-hour window, 1H resample):\n",
    "  - Why: using a fixed early-window (e.g., first 72 hours) standardizes inputs and focuses on early inpatient signals that could predict readmission risk. Hourly resampling balances temporal resolution and computational cost.\n",
    "  - Alternatives: longer windows or different pooling (min/max/last/percentiles) depending on the problem framing.\n",
    "\n",
    "- Imputation strategy (linear interpolation then mean fill):\n",
    "  - Why: clinical time series are irregular; interpolation fills short gaps while forward/backward filling and mean imputation handle longer missing stretches. This is a pragmatic choice for baseline models.\n",
    "  - Caveat: imputation can leak future info if misused (we only interpolate inside the admission window from observed times). For causal/time-to-event work, prefer models that handle irregular time or explicit missingness indicators.\n",
    "\n",
    "- Pooling into summary stats (mean, std, min, max):\n",
    "  - Why: reduces time-series to compact fixed-length vectors suitable for classical ML baselines (LogReg, RF) and quick experiments. These pooled features are interpretable and fast.\n",
    "  - Next step: use sequence models (LSTM/Transformer) on full time-series for richer temporal modeling.\n",
    "\n",
    "- Class weighting and stratified CV:\n",
    "  - Why: readmission is imbalanced (~20% positive in your preview). Using `class_weight='balanced'` and stratified splits makes training and evaluation more robust and comparable.\n",
    "\n",
    "Caveats & next improvements:\n",
    "- Add explicit cohort exclusions (planned readmissions, transfers, hospice, death during stay) depending on your study design.\n",
    "- Save parsing logs (rows parsed, NaT count) to detect data drift or broken exports.\n",
    "- Consider more advanced imputation (KNN, learned imputers) or models that explicitly handle missingness.\n",
    "- For reproducibility, pin the random seed and record data slices used for smoke tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e7c91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting smoke test: time-series pooling + imputation + quick CV...\n",
      "static_df not found in memory — constructing from admissions & patients (this may take a few seconds)\n",
      "Constructed static_df; sample:\n",
      "   subject_id   hadm_id  age  los_days  readmit_30d\n",
      "0    10000032  22595853   52  0.786111            0\n",
      "1    10000032  22841357   52  1.015278            1\n",
      "2    10000032  29079034   52  2.222222            1\n",
      "3    10000032  25742920   52  1.754167            0\n",
      "4    10000068  25022803   19  0.298611            0\n",
      "Loading small slices of chartevents/labevents (this may still take a few seconds)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:134: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  combined = combined.resample(resample_freq).mean()\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  pad_df = pd.DataFrame(np.nan, index=pd.date_range(ts.index[-1]+pd.Timedelta(hours=1), periods=pad_len, freq='1H'), columns=ts.columns)\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:134: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  combined = combined.resample(resample_freq).mean()\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  pad_df = pd.DataFrame(np.nan, index=pd.date_range(ts.index[-1]+pd.Timedelta(hours=1), periods=pad_len, freq='1H'), columns=ts.columns)\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:134: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  combined = combined.resample(resample_freq).mean()\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  pad_df = pd.DataFrame(np.nan, index=pd.date_range(ts.index[-1]+pd.Timedelta(hours=1), periods=pad_len, freq='1H'), columns=ts.columns)\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:134: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  combined = combined.resample(resample_freq).mean()\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  pad_df = pd.DataFrame(np.nan, index=pd.date_range(ts.index[-1]+pd.Timedelta(hours=1), periods=pad_len, freq='1H'), columns=ts.columns)\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:134: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  combined = combined.resample(resample_freq).mean()\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  pad_df = pd.DataFrame(np.nan, index=pd.date_range(ts.index[-1]+pd.Timedelta(hours=1), periods=pad_len, freq='1H'), columns=ts.columns)\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:134: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  combined = combined.resample(resample_freq).mean()\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  pad_df = pd.DataFrame(np.nan, index=pd.date_range(ts.index[-1]+pd.Timedelta(hours=1), periods=pad_len, freq='1H'), columns=ts.columns)\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:134: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  combined = combined.resample(resample_freq).mean()\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  pad_df = pd.DataFrame(np.nan, index=pd.date_range(ts.index[-1]+pd.Timedelta(hours=1), periods=pad_len, freq='1H'), columns=ts.columns)\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:134: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  combined = combined.resample(resample_freq).mean()\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  pad_df = pd.DataFrame(np.nan, index=pd.date_range(ts.index[-1]+pd.Timedelta(hours=1), periods=pad_len, freq='1H'), columns=ts.columns)\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:134: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  combined = combined.resample(resample_freq).mean()\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  pad_df = pd.DataFrame(np.nan, index=pd.date_range(ts.index[-1]+pd.Timedelta(hours=1), periods=pad_len, freq='1H'), columns=ts.columns)\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:134: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  combined = combined.resample(resample_freq).mean()\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  pad_df = pd.DataFrame(np.nan, index=pd.date_range(ts.index[-1]+pd.Timedelta(hours=1), periods=pad_len, freq='1H'), columns=ts.columns)\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:134: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  combined = combined.resample(resample_freq).mean()\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:134: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  combined = combined.resample(resample_freq).mean()\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  pad_df = pd.DataFrame(np.nan, index=pd.date_range(ts.index[-1]+pd.Timedelta(hours=1), periods=pad_len, freq='1H'), columns=ts.columns)\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:134: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  combined = combined.resample(resample_freq).mean()\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  pad_df = pd.DataFrame(np.nan, index=pd.date_range(ts.index[-1]+pd.Timedelta(hours=1), periods=pad_len, freq='1H'), columns=ts.columns)\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:134: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  combined = combined.resample(resample_freq).mean()\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  pad_df = pd.DataFrame(np.nan, index=pd.date_range(ts.index[-1]+pd.Timedelta(hours=1), periods=pad_len, freq='1H'), columns=ts.columns)\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:134: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  combined = combined.resample(resample_freq).mean()\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  pad_df = pd.DataFrame(np.nan, index=pd.date_range(ts.index[-1]+pd.Timedelta(hours=1), periods=pad_len, freq='1H'), columns=ts.columns)\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:134: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  combined = combined.resample(resample_freq).mean()\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  pad_df = pd.DataFrame(np.nan, index=pd.date_range(ts.index[-1]+pd.Timedelta(hours=1), periods=pad_len, freq='1H'), columns=ts.columns)\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:134: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  combined = combined.resample(resample_freq).mean()\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  pad_df = pd.DataFrame(np.nan, index=pd.date_range(ts.index[-1]+pd.Timedelta(hours=1), periods=pad_len, freq='1H'), columns=ts.columns)\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:134: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  combined = combined.resample(resample_freq).mean()\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  pad_df = pd.DataFrame(np.nan, index=pd.date_range(ts.index[-1]+pd.Timedelta(hours=1), periods=pad_len, freq='1H'), columns=ts.columns)\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:134: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  combined = combined.resample(resample_freq).mean()\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  pad_df = pd.DataFrame(np.nan, index=pd.date_range(ts.index[-1]+pd.Timedelta(hours=1), periods=pad_len, freq='1H'), columns=ts.columns)\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:134: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  combined = combined.resample(resample_freq).mean()\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  pad_df = pd.DataFrame(np.nan, index=pd.date_range(ts.index[-1]+pd.Timedelta(hours=1), periods=pad_len, freq='1H'), columns=ts.columns)\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:134: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  combined = combined.resample(resample_freq).mean()\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  pad_df = pd.DataFrame(np.nan, index=pd.date_range(ts.index[-1]+pd.Timedelta(hours=1), periods=pad_len, freq='1H'), columns=ts.columns)\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:134: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  combined = combined.resample(resample_freq).mean()\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  pad_df = pd.DataFrame(np.nan, index=pd.date_range(ts.index[-1]+pd.Timedelta(hours=1), periods=pad_len, freq='1H'), columns=ts.columns)\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:134: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  combined = combined.resample(resample_freq).mean()\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  pad_df = pd.DataFrame(np.nan, index=pd.date_range(ts.index[-1]+pd.Timedelta(hours=1), periods=pad_len, freq='1H'), columns=ts.columns)\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:134: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  combined = combined.resample(resample_freq).mean()\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  pad_df = pd.DataFrame(np.nan, index=pd.date_range(ts.index[-1]+pd.Timedelta(hours=1), periods=pad_len, freq='1H'), columns=ts.columns)\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:134: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  combined = combined.resample(resample_freq).mean()\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  pad_df = pd.DataFrame(np.nan, index=pd.date_range(ts.index[-1]+pd.Timedelta(hours=1), periods=pad_len, freq='1H'), columns=ts.columns)\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:134: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  combined = combined.resample(resample_freq).mean()\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  pad_df = pd.DataFrame(np.nan, index=pd.date_range(ts.index[-1]+pd.Timedelta(hours=1), periods=pad_len, freq='1H'), columns=ts.columns)\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:134: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  combined = combined.resample(resample_freq).mean()\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  pad_df = pd.DataFrame(np.nan, index=pd.date_range(ts.index[-1]+pd.Timedelta(hours=1), periods=pad_len, freq='1H'), columns=ts.columns)\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:134: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  combined = combined.resample(resample_freq).mean()\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  pad_df = pd.DataFrame(np.nan, index=pd.date_range(ts.index[-1]+pd.Timedelta(hours=1), periods=pad_len, freq='1H'), columns=ts.columns)\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:134: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  combined = combined.resample(resample_freq).mean()\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  pad_df = pd.DataFrame(np.nan, index=pd.date_range(ts.index[-1]+pd.Timedelta(hours=1), periods=pad_len, freq='1H'), columns=ts.columns)\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:134: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  combined = combined.resample(resample_freq).mean()\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  pad_df = pd.DataFrame(np.nan, index=pd.date_range(ts.index[-1]+pd.Timedelta(hours=1), periods=pad_len, freq='1H'), columns=ts.columns)\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:134: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  combined = combined.resample(resample_freq).mean()\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  pad_df = pd.DataFrame(np.nan, index=pd.date_range(ts.index[-1]+pd.Timedelta(hours=1), periods=pad_len, freq='1H'), columns=ts.columns)\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:134: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  combined = combined.resample(resample_freq).mean()\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  pad_df = pd.DataFrame(np.nan, index=pd.date_range(ts.index[-1]+pd.Timedelta(hours=1), periods=pad_len, freq='1H'), columns=ts.columns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built small dataset shapes: (34, 2) (34, 72, 9) (34,)\n",
      "Final pooled feature shape: (34, 38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:134: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  combined = combined.resample(resample_freq).mean()\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  pad_df = pd.DataFrame(np.nan, index=pd.date_range(ts.index[-1]+pd.Timedelta(hours=1), periods=pad_len, freq='1H'), columns=ts.columns)\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:134: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  combined = combined.resample(resample_freq).mean()\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:161: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  pad_df = pd.DataFrame(np.nan, index=pd.date_range(ts.index[-1]+pd.Timedelta(hours=1), periods=pad_len, freq='1H'), columns=ts.columns)\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:200: RuntimeWarning: Mean of empty slice\n",
      "  mean = np.nanmean(arr, axis=0)\n",
      "/opt/anaconda3/envs/mimic-py311/lib/python3.11/site-packages/numpy/lib/_nanfunctions_impl.py:2053: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:202: RuntimeWarning: All-NaN slice encountered\n",
      "  mn = np.nanmin(arr, axis=0)\n",
      "/var/folders/v0/1lrkgf3s4d3_x4q14m3pmy840000gn/T/ipykernel_92993/2906703046.py:203: RuntimeWarning: All-NaN slice encountered\n",
      "  mx = np.nanmax(arr, axis=0)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'RANDOM_SEED' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 218\u001b[39m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m     Xtr, Xte, ytr, yte = train_test_split(X_final_small, y_small, test_size=\u001b[32m0.3\u001b[39m, random_state=\u001b[43mRANDOM_SEED\u001b[49m, stratify=y_small)\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[31mNameError\u001b[39m: name 'RANDOM_SEED' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 220\u001b[39m\n\u001b[32m    218\u001b[39m     Xtr, Xte, ytr, yte = train_test_split(X_final_small, y_small, test_size=\u001b[32m0.3\u001b[39m, random_state=RANDOM_SEED, stratify=y_small)\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m     Xtr, Xte, ytr, yte = train_test_split(X_final_small, y_small, test_size=\u001b[32m0.3\u001b[39m, random_state=\u001b[43mRANDOM_SEED\u001b[49m)\n\u001b[32m    222\u001b[39m lr = LogisticRegression(max_iter=\u001b[32m1000\u001b[39m, class_weight=\u001b[33m'\u001b[39m\u001b[33mbalanced\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    223\u001b[39m rf = RandomForestClassifier(n_estimators=\u001b[32m100\u001b[39m, random_state=RANDOM_SEED, class_weight=\u001b[33m'\u001b[39m\u001b[33mbalanced\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'RANDOM_SEED' is not defined"
     ]
    }
   ],
   "source": [
    "# --------- Time-series pooling, imputation, and small smoke test (nrows) ---------\n",
    "print('Starting smoke test: time-series pooling + imputation + quick CV...')\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import pandas as pd\n",
    "\n",
    "# Default seed if not set earlier\n",
    "if 'RANDOM_SEED' not in globals():\n",
    "    RANDOM_SEED = 42\n",
    "\n",
    "# Ensure core dataframes exist; if not, load/compute them (makes this cell runnable standalone)\n",
    "if 'static_df' not in globals():\n",
    "    print('static_df not found in memory — constructing from admissions & patients (this may take a few seconds)')\n",
    "    def _parse_dates_if_exists(df, cols):\n",
    "        for col in cols:\n",
    "            if col in df.columns:\n",
    "                df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "        return df\n",
    "    def _read(path, **kwargs):\n",
    "        if os.path.exists(path):\n",
    "            return pd.read_csv(path, **kwargs)\n",
    "        raise FileNotFoundError(path)\n",
    "\n",
    "    admissions = pd.read_csv(os.path.join(DATA_DIR, 'hosp', 'admissions.csv'))\n",
    "    admissions = _parse_dates_if_exists(admissions, ['admittime', 'dischtime', 'deathtime', 'edregtime', 'edouttime'])\n",
    "    admissions = admissions.sort_values(['subject_id', 'admittime']).reset_index(drop=True)\n",
    "\n",
    "    # compute readmit_30d if missing\n",
    "    if 'readmit_30d' not in admissions.columns:\n",
    "        readmit_30d = []\n",
    "        for idx, row in admissions.iterrows():\n",
    "            subject_id = row['subject_id']\n",
    "            hadm_id = row['hadm_id']\n",
    "            dischtime = row['dischtime']\n",
    "            if pd.isna(dischtime):\n",
    "                readmit_30d.append(0)\n",
    "                continue\n",
    "            future_admissions = admissions[\n",
    "                (admissions['subject_id'] == subject_id) &\n",
    "                (admissions['hadm_id'] != hadm_id) &\n",
    "                (admissions['admittime'] > dischtime)\n",
    "            ]\n",
    "            if not future_admissions.empty:\n",
    "                next_admit = future_admissions.iloc[0]['admittime']\n",
    "                days_to_readmit = (next_admit - dischtime).total_seconds() / (24*3600)\n",
    "                readmit_30d.append(1 if days_to_readmit <= 30 else 0)\n",
    "            else:\n",
    "                readmit_30d.append(0)\n",
    "        admissions['readmit_30d'] = readmit_30d\n",
    "    \n",
    "    # load patients and merge anchor_age/year\n",
    "    patients = _read(os.path.join(DATA_DIR, 'hosp', 'patients.csv'))\n",
    "    if 'anchor_age' in patients.columns and 'anchor_year' in patients.columns:\n",
    "        admissions = admissions.merge(patients[['subject_id','anchor_age','anchor_year']], on='subject_id', how='left')\n",
    "        admissions['admit_year'] = admissions['admittime'].dt.year\n",
    "        admissions['age'] = admissions['anchor_age'] + (admissions['admit_year'] - admissions['anchor_year'])\n",
    "        admissions['age'] = admissions['age'].clip(lower=0)\n",
    "    else:\n",
    "        # Fallback if anchor_age/year missing\n",
    "        admissions['age'] = np.nan\n",
    "\n",
    "    admissions['los_days'] = (admissions['dischtime'] - admissions['admittime']).dt.total_seconds()/(3600*24)\n",
    "    static_df = admissions[['subject_id','hadm_id','age','los_days','readmit_30d']].drop_duplicates().reset_index(drop=True)\n",
    "    print('Constructed static_df; sample:')\n",
    "    print(static_df.head())\n",
    "\n",
    "# Read small chunks of chartevents / labevents for smoke testing (adjust nrows as needed)\n",
    "ce_path = os.path.join(DATA_DIR, 'icu', 'chartevents.csv')\n",
    "le_path = os.path.join(DATA_DIR, 'hosp', 'labevents.csv')\n",
    "\n",
    "# Guard: if files absent, skip\n",
    "if not os.path.exists(ce_path) or not os.path.exists(le_path):\n",
    "    print('chartevents or labevents not found; skipping smoke test of time-series.')\n",
    "else:\n",
    "    print('Loading small slices of chartevents/labevents (this may still take a few seconds)...')\n",
    "    try:\n",
    "        ce = pd.read_csv(ce_path, usecols=['subject_id','hadm_id','charttime','itemid','valuenum','value'], nrows=200000, low_memory=False)\n",
    "    except Exception:\n",
    "        ce = pd.read_csv(ce_path, nrows=200000, low_memory=False)\n",
    "    try:\n",
    "        le = pd.read_csv(le_path, usecols=['labevent_id','subject_id','hadm_id','charttime','itemid','valuenum','value'], nrows=50000, low_memory=False)\n",
    "    except Exception:\n",
    "        le = pd.read_csv(le_path, nrows=50000, low_memory=False)\n",
    "\n",
    "    # use lowercase 'h' for resampling compatibility warnings\n",
    "    ce = _parse_dates_if_exists(ce, ['charttime'])\n",
    "    le = _parse_dates_if_exists(le, ['charttime'])\n",
    "\n",
    "    # Define simple item lists (same as template) — these are examples and can be customized\n",
    "    vital_items_of_interest = {\n",
    "        'heart_rate': [211, 220045],\n",
    "        'sys_bp': [220179, 51],\n",
    "        'dias_bp': [220180, 8368],\n",
    "        'resp_rate': [220210, 618],\n",
    "        'temp': [223761, 678],\n",
    "        'spo2': [220277]\n",
    "    }\n",
    "    lab_items_of_interest = {\n",
    "        'creatinine': [50912],\n",
    "        'glucose': [807, 823],\n",
    "        'wbc': [730],\n",
    "    }\n",
    "\n",
    "    def get_patient_events_smoke(hadm_id, window_hours=72, resample_freq='1h'):\n",
    "        # Use the small loaded slices (ce, le) — return None if no data\n",
    "        adm_row = admissions[admissions['hadm_id']==hadm_id]\n",
    "        if adm_row.empty:\n",
    "            return None\n",
    "        t0 = adm_row.iloc[0]['admittime']\n",
    "        t_end = t0 + pd.Timedelta(hours=window_hours)\n",
    "        ce_sub = ce[(ce['hadm_id']==hadm_id) & (ce['charttime']>=t0) & (ce['charttime']<=t_end)] if not ce.empty else pd.DataFrame()\n",
    "        le_sub = le[(le['hadm_id']==hadm_id) & (le['charttime']>=t0) & (le['charttime']<=t_end)] if not le.empty else pd.DataFrame()\n",
    "        rows = []\n",
    "        for var, itemids in vital_items_of_interest.items():\n",
    "            if ce_sub.empty:\n",
    "                continue\n",
    "            tmp = ce_sub[ce_sub['itemid'].isin(itemids)][['charttime','valuenum']].dropna()\n",
    "            if tmp.empty:\n",
    "                continue\n",
    "            tmp = tmp.rename(columns={'charttime':'time','valuenum':var})\n",
    "            tmp[var] = pd.to_numeric(tmp[var], errors='coerce')\n",
    "            rows.append(tmp.set_index('time')[var])\n",
    "        for var, itemids in lab_items_of_interest.items():\n",
    "            if le_sub.empty:\n",
    "                continue\n",
    "            tmp = le_sub[le_sub['itemid'].isin(itemids)][['charttime','valuenum']].dropna()\n",
    "            if tmp.empty:\n",
    "                continue\n",
    "            tmp = tmp.rename(columns={'charttime':'time','valuenum':var})\n",
    "            tmp[var] = pd.to_numeric(tmp[var], errors='coerce')\n",
    "            rows.append(tmp.set_index('time')[var])\n",
    "        if not rows:\n",
    "            return None\n",
    "        combined = pd.concat(rows, axis=1)\n",
    "        combined = combined.resample(resample_freq).mean()\n",
    "        combined = combined[:t0 + pd.Timedelta(hours=window_hours)]\n",
    "        return combined\n",
    "\n",
    "    # Build a small dataset for first N hadm_ids\n",
    "    hadm_ids_small = static_df['hadm_id'].dropna().unique()[:50]\n",
    "    X_static_small = []\n",
    "    X_ts_small = []\n",
    "    y_small = []\n",
    "    all_cols = list(vital_items_of_interest.keys()) + list(lab_items_of_interest.keys())\n",
    "\n",
    "    for hid in hadm_ids_small:\n",
    "        s = static_df[static_df['hadm_id']==hid]\n",
    "        if s.empty:\n",
    "            continue\n",
    "        ts = get_patient_events_smoke(hid, window_hours=72, resample_freq='1h')\n",
    "        if ts is None:\n",
    "            continue\n",
    "        for c in all_cols:\n",
    "            if c not in ts.columns:\n",
    "                ts[c] = np.nan\n",
    "        ts = ts[all_cols]\n",
    "        # ensure TIMESTEPS\n",
    "        if len(ts) < 72:\n",
    "            pad_len = 72 - len(ts)\n",
    "            if len(ts) == 0:\n",
    "                continue\n",
    "            pad_df = pd.DataFrame(np.nan, index=pd.date_range(ts.index[-1]+pd.Timedelta(hours=1), periods=pad_len, freq='1h'), columns=ts.columns)\n",
    "            ts = pd.concat([ts, pad_df])\n",
    "        else:\n",
    "            ts = ts.iloc[:72]\n",
    "        # Static selection: age and los_days (if los_days NaN, fill 0)\n",
    "        s_age = s['age'].iloc[0] if not pd.isna(s['age'].iloc[0]) else 0.0\n",
    "        s_los = s['los_days'].iloc[0] if not pd.isna(s['los_days'].iloc[0]) else 0.0\n",
    "        X_static_small.append(np.array([s_age, s_los], dtype=float))\n",
    "        X_ts_small.append(ts.values.astype(float))\n",
    "        y_small.append(int(s['readmit_30d'].iloc[0]))\n",
    "\n",
    "    X_static_small = np.array(X_static_small)\n",
    "    X_ts_small = np.array(X_ts_small)\n",
    "    y_small = np.array(y_small)\n",
    "\n",
    "    if len(y_small) == 0:\n",
    "        print('No time-series data available for the small sample with the chosen item lists. Consider increasing nrows or adjusting itemid lists.')\n",
    "    else:\n",
    "        print('Built small dataset shapes:', X_static_small.shape, X_ts_small.shape, y_small.shape)\n",
    "\n",
    "        # Impute time-series\n",
    "        def impute_time_series_array(X_ts):\n",
    "            N, T, F = X_ts.shape\n",
    "            X_imputed = X_ts.copy()\n",
    "            for i in range(N):\n",
    "                df_ts = pd.DataFrame(X_ts[i], columns=[f'f{j}' for j in range(F)])\n",
    "                df_ts = df_ts.interpolate(method='linear', limit_direction='both', axis=0).ffill().bfill()\n",
    "                df_ts = df_ts.fillna(df_ts.mean())\n",
    "                X_imputed[i] = df_ts.values\n",
    "            return X_imputed\n",
    "\n",
    "        X_ts_imputed_small = impute_time_series_array(X_ts_small)\n",
    "\n",
    "        # Pool time-series features\n",
    "        def pool_time_series_features(X_ts):\n",
    "            N, T, F = X_ts.shape\n",
    "            feats = []\n",
    "            for i in range(N):\n",
    "                arr = X_ts[i]\n",
    "                mean = np.nanmean(arr, axis=0)\n",
    "                std = np.nanstd(arr, axis=0)\n",
    "                mn = np.nanmin(arr, axis=0)\n",
    "                mx = np.nanmax(arr, axis=0)\n",
    "                # Handle all-NaN columns by replacing with zeros (safe for small baseline models)\n",
    "                mean = np.nan_to_num(mean, nan=0.0)\n",
    "                std = np.nan_to_num(std, nan=0.0)\n",
    "                mn = np.nan_to_num(mn, nan=0.0)\n",
    "                mx = np.nan_to_num(mx, nan=0.0)\n",
    "                feats.append(np.concatenate([mean, std, mn, mx]))\n",
    "            return np.array(feats)\n",
    "\n",
    "        X_pool_small = pool_time_series_features(X_ts_imputed_small)\n",
    "\n",
    "        # Scale static features\n",
    "        scaler_small = StandardScaler()\n",
    "        X_static_scaled_small = scaler_small.fit_transform(X_static_small)\n",
    "\n",
    "        X_final_small = np.hstack([X_static_scaled_small, X_pool_small])\n",
    "        print('Final pooled feature shape:', X_final_small.shape)\n",
    "\n",
    "        # Quick train/test split and evaluation\n",
    "        try:\n",
    "            if len(np.unique(y_small))>1:\n",
    "                Xtr, Xte, ytr, yte = train_test_split(X_final_small, y_small, test_size=0.3, random_state=RANDOM_SEED, stratify=y_small)\n",
    "            else:\n",
    "                Xtr, Xte, ytr, yte = train_test_split(X_final_small, y_small, test_size=0.3, random_state=RANDOM_SEED)\n",
    "        except Exception:\n",
    "            Xtr, Xte, ytr, yte = train_test_split(X_final_small, y_small, test_size=0.3, random_state=RANDOM_SEED)\n",
    "\n",
    "        lr = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "        rf = RandomForestClassifier(n_estimators=100, random_state=RANDOM_SEED, class_weight='balanced')\n",
    "\n",
    "        lr.fit(Xtr, ytr)\n",
    "        rf.fit(Xtr, ytr)\n",
    "\n",
    "        lr_p = lr.predict_proba(Xte)[:,1]\n",
    "        rf_p = rf.predict_proba(Xte)[:,1]\n",
    "\n",
    "        print('Smoke test results:')\n",
    "        if len(set(yte))>1:\n",
    "            print('LR AUROC:', roc_auc_score(yte, lr_p), 'AUPRC:', average_precision_score(yte, lr_p))\n",
    "            print('RF AUROC:', roc_auc_score(yte, rf_p), 'AUPRC:', average_precision_score(yte, rf_p))\n",
    "        else:\n",
    "            print('Insufficient label variation in test split to compute AUROC/AUPRC.')\n",
    "\n",
    "print('Smoke test complete.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mimic-py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
